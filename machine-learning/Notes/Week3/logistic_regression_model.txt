Cost function
-------------

How do we come up with the paramter theta?

cost for linear regression
J = 1/m * (sum for all samples) [ 1/2 * (h (theta) (x) - y ) ^ 2]

cost = 1/2  * (h (theta) (x) - y) ^ 2

This function does not work for logistic regression since it is non-convex i.e.
there are multiple local minimas. We need to have a function that is convex
that has just one local minima which also happens to be the global minima of the
cost function.

Cost function for logistic regression

cost = -log(h(x) if y =1
		-log(1-h(x)) if y = 0

This cost function is desirable for the following properties:

When y = 1
1) if y = 1 and h(x) = 1, cost = 0 i.e. prediction is correct.
2) if h(x) -> 0 , cost tends to infinity.
3) if h(x) = 0, and y =1, (worst prediction), cost tends to infinity
meaning we will penalize the learning algo by a large cost.

When y = 0
1) when y =0, h(x) = 0, learning algo nailed it
2) when y = 0 and h(x) = 1 (worst prediction), cost tends to infinity

Simplified Cost function
-------------------------
incorporate y variable into the cost function.

Gradient descent
----------------

Addressing the question: how do we come up with theta?

the update rule for theta is identical to that of what was used for linear
regression. The only difference is that h(x) definition is different
for the two models....i.e

h(x) = theta' * x (for linear regression)

h(x) = g( theta' * x) where g() is the sigmoid function (for logistic regression)


Advanced Optimization
----------------------
Gradient descent is not the only option for optimization.

Other options:
1) Conjugate gradient
2) BFGS (?)
3) L-BFGS (?)

Advantages:
1) Dont need to supply learning rate, alpha for these methods (computes learning rate automatically)
2) Converges much faster than graident descent.

Cons:
1) Much more complex than gradient descent. (use already existing libraries instead of implementing your own)


